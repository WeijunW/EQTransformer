{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (II) Detection and Picking\n",
    "This notebook demonstrates the use of EQTransformer for performing the earthquake signal detection and seismic phase (P & S) picking on continuous data. Once you have your seismic data - preferentially in mseed format and in individual subfolders for each station- you can perform the detection/picking using the following options:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option (I) on preprocessed (hdf5) files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option is recommended for smaller time periods (a few days to a month). This allows you to test the perfomance and explore the effects of different parameters while the provided hdf5 file makes it easy to access the waveforms.\n",
    "\n",
    "For this option you first need to convert your MiniSeed files for each station into a single hdf5 file and a csv file containting the list of traces in the hdf5 file.\n",
    "\n",
    "You can convert MiniSeed files to a hdf5 file using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 16:37:13.131269: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from EQTransformer.utils.hdf5_maker import preprocessor\n",
    "\n",
    "json_basepath = os.path.join(os.getcwd(),\"json/station_list.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor(preproc_dir=\"preproc\",\n",
    "             mseed_dir='downloads_mseeds', \n",
    "             stations_json=json_basepath, \n",
    "             overlap=0.3, \n",
    "             n_processor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate one \"station_name.hdf5\" and one \"station_name.csv\" file for each of your stations and put them into a directory named \"mseed_dir+_hdfs\". Then you need to pass the name of the directory containing your hdf5 & CSV files and a model. You can use relatively low threshold values for the detection and picking since EQTransformer is very robust to false positives. Enabling uncertaintiy estimation, outputing probabilities, or plotting all the detected events will slow down the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.core.predictor import predictor\n",
    "predictor(input_dir='downloads_mseeds_processed_hdfs',   \n",
    "         input_model='../ModelsAndSampleData/EqT_model.h5',\n",
    "         output_dir='detections1',\n",
    "         estimate_uncertainty=False, \n",
    "         output_probabilities=False,\n",
    "         number_of_sampling=5,\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.1,\n",
    "         S_threshold=0.1, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time',\n",
    "         batch_size=500,\n",
    "         number_of_cpus=4,\n",
    "         keepPS=False,\n",
    "         spLimit=60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using local MiniSeed files you can generate a station_list.json by supplying an absolute path to a directory containing Miniseed files and a station location dictionary using the stationListFromMseed function like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.utils.hdf5_maker import stationListFromMseed\n",
    "\n",
    "mseed_directory = '/Users/username/Downloads/EQTransformer/examples/downloads_mseeds'\n",
    "station_locations = {\"CA06\": [35.59962, -117.49268, 796.4], \"CA10\": [35.56736, -117.667427, 835.9]}\n",
    "stationListFromMseed(mseed_directory, station_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option (II) directly on downloaded MiniSeed files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform the detection/picking directly on .mseed files. \n",
    "This save both prerpcessing time and the extra space needed for hdf5 file. However, it can be more memory intensive. So it is recommended when mseed fils are one month long or shorter.\n",
    "This option also does not allow you to estimate the uncertainties, write the prediction probabilities, or use the advantages of having hdf5 files which makes it easy to access the raw event waveforms based on detection results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.core.mseed_predictor import mseed_predictor\n",
    "mseed_predictor(input_dir='downloads_mseeds',   \n",
    "         input_model='../ModelsAndSampleData/EqT_model2.h5',\n",
    "         stations_json=json_basepath,\n",
    "         output_dir='detections2',\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.1,\n",
    "         S_threshold=0.1, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time_frequency',\n",
    "         normalization_mode='std',\n",
    "         batch_size=500,\n",
    "         overlap=0.3,\n",
    "         gpuid=None,\n",
    "         gpu_limit=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction outputs for each station will be written in your output directory (i.e. 'detections').\n",
    "\n",
    "'X_report.txt' contains processing info on input parameters used for the detection/picking and final \n",
    "results such as running time, the total number of detected events (these are unique events and duplicated ones have been already removed). \n",
    "\n",
    "'X_prediction_results.csv' contains detection/picking results in the figures folder you can find the plots for the number of events that you specified in the above comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 18:34:36.379321: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "05-04 18:34 [INFO] [EQTransformer] Running EqTransformer  0.1.61\n",
      "05-04 18:34 [INFO] [EQTransformer] *** Loading the model ...\n",
      "05-04 18:34 [DEBUG] [h5py._conv] Creating converter from 3 to 5\n",
      "2022-05-04 18:34:38.069090: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-04 18:34:38.083048: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-05-04 18:34:38.083075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: d7540\n",
      "2022-05-04 18:34:38.083080: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: d7540\n",
      "2022-05-04 18:34:38.083139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
      "2022-05-04 18:34:38.083156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
      "2022-05-04 18:34:38.083161: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
      "2022-05-04 18:34:38.083702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "05-04 18:34 [INFO] [EQTransformer] *** Loading is complete!\n",
      "05-04 18:34 [INFO] [EQTransformer] *** /home/wwj/oldhome/wwj/gitwork/detect_locate/EQTransformer/examples/detections_sds already exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA06 : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 18:34:45.202821: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-04 18:34:45.214513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B921 : 6\n",
      "SV08 : 3\n",
      "CA06 : 3\n",
      "B921 : 3\n",
      "SV08 : 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#from EQTransformer.utils.hdf5_maker import preprocessor\n",
    "\n",
    "json_basepath = os.path.join(os.getcwd(),\"json/station_list_sds.json\")\n",
    "\n",
    "from EQTransformer.core.mseed_predictor import sds_predictor\n",
    "from obspy import UTCDateTime\n",
    "sdsdir='/home/wwj/Data/waves/waves'\n",
    "t1 = UTCDateTime('2019-09-01:00:00')\n",
    "t2 = UTCDateTime('2019-09-03:00:00')\n",
    "sds_predictor(t1,t2,sds_dir=sdsdir,   \n",
    "         input_model='../ModelsAndSampleData/EqT_model2.h5',\n",
    "         stations_json=json_basepath,\n",
    "         output_dir='detections_sds',\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.1,\n",
    "         S_threshold=0.1, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time_frequency',\n",
    "         normalization_mode='std',\n",
    "         batch_size=500,\n",
    "         overlap=0.3,\n",
    "         gpuid=None,\n",
    "         gpu_limit=None) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
